{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "98618fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import numpy as np \n",
    "import random \n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pylab as pl\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9cd2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "class_list = ['Batman', 'Spiderman', 'None']\n",
    "\n",
    "\n",
    "Width = 256\n",
    "Height = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052a1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(path):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89797652",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = {}\n",
    "for training_name in class_list:\n",
    "    dir_= os.path.join(data_dir, training_name)\n",
    "    class_path = get_file_names(dir_)\n",
    "    image_paths[training_name] = class_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a868b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'Batman':0, 'Spiderman':1, 'None':2}\n",
    "image_data = []\n",
    "for k, v in image_paths.items():\n",
    "    for im in v: \n",
    "        image_data.append((im, label_dict[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "779bc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(image_data)\n",
    "image_paths, labels = zip(*image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a02f5dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "des_list=[]\n",
    "hog = cv2.HOGDescriptor()\n",
    "\n",
    "# https://stackoverflow.com/questions/44972099/opencv-hog-features-explanation\n",
    "# https://answers.opencv.org/question/86023/what-is-the-hog-descriptors-shape/\n",
    "#\n",
    "\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(path)\n",
    "    resized_image = []\n",
    "    for i in range(3): \n",
    "        resized_image.append(cv2.resize(img[:,:,i], (128,64)))\n",
    "    resized_image = np.array(resized_image).reshape(128,64,3)\n",
    "    #creating hog features \n",
    "    descriptor = hog.compute(resized_image)\n",
    "    des_list.append((path,np.array(descriptor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2a02d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.split('/')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e098f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_features = []\n",
    "image_labels = []\n",
    "BoW = []\n",
    "BoW_labels = [] \n",
    "for i in range(len(des_list)): \n",
    "    temp_des = des_list[i][1]\n",
    "    reshaped_features.append(temp_des.reshape(15*7,-1))\n",
    "    image_labels.append(label_dict[des_list[i][0].split('/')[2]])\n",
    "    for j in range(reshaped_features[i].shape[0]):\n",
    "        BoW.append(reshaped_features[i][j])\n",
    "        BoW_labels.append(des_list[i][0].split('/')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e34040b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW_array = np.array(BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7b0115a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22575, 36)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "768c7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_histogram(descriptor_list, cluster_alg):\n",
    "    histogram = np.zeros(len(cluster_alg.cluster_centers_))\n",
    "    cluster_result =  cluster_alg.predict(descriptor_list)\n",
    "    for i in cluster_result:\n",
    "        histogram[i] += 1.0\n",
    "    return histogram\n",
    "\n",
    "kmeans = KMeans(n_clusters = 256)\n",
    "kmeans.fit(BoW_array)\n",
    "\n",
    "preprocessed_image = []\n",
    "\n",
    "for descriptor in reshaped_features:\n",
    "    if (descriptor is not None):\n",
    "        temp_features = []\n",
    "        for piece in descriptor: \n",
    "            histogram = build_histogram(piece.reshape(1,-1), kmeans)  # getting histogram for each piece \n",
    "            temp_features.append(histogram)\n",
    "        temp_features = np.sum(np.array(temp_features), 0)\n",
    "        preprocessed_image.append(temp_features.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c60d18a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 2., 0., 2., 0., 0., 0., 1., 0., 2., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 2., 0., 0., 0., 0., 1., 2., 0., 0., 0., 0., 0., 0., 3., 0.,\n",
       "       2., 0., 0., 0., 0., 0., 4., 0., 0., 0., 2., 0., 0., 0., 1., 0., 3.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 3., 0., 0.,\n",
       "       1., 0., 2., 0., 2., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 2., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 2., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 2.,\n",
       "       0.])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "73d0a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(preprocessed_image, image_labels,\n",
    "                                                    test_size = .25, random_state = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "226e6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = { \n",
    "    'C': [2**(-5), 2**(-4), 2**(-3), 2**(-2), 2**(-1), 1, 2, 4 ,8 ,16],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "}\n",
    "\n",
    "# grid = { \n",
    "#     'C': [2**(-5),  2**(-3), 1, 4 ,16],\n",
    "#     'kernel': ['linear', 'rbf'],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "40bf9e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8,\n",
       "                               16],\n",
       "                         'kernel': ['linear', 'poly', 'rbf']})"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv = GridSearchCV(estimator=SVC(), param_grid=grid, cv= 5)\n",
    "svm_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "46866a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.03125, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(svm_cv.best_params_)\n",
    "best_param = svm_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8d4b41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'best_param_limmited.pkl'\n",
    "with open(pickle_file_name, 'wb') as handle:\n",
    "    pickle.dump(svm_cv.best_params_, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4c721e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'best_param_limmited.pkl'\n",
    "if os.path.exists(pickle_file_name):\n",
    "    with open(pickle_file_name, 'rb') as handle:\n",
    "        best_param = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "162ab2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.03125, kernel='poly')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(**best_param)\n",
    "svm_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7d843b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c2c6e4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46296296296296297"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e073de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess image\n",
    "def constrastLimit(image):\n",
    "    img_hist_equalized = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "#    channels = cv2.split(img_hist_equalized)\n",
    "#    channels[0] = cv2.equalizeHist(channels[0])\n",
    "#    img_hist_equalized = cv2.merge(channels)\n",
    "    y, cr, cb = cv2.split(img_hist_equalized)\n",
    "    y = cv2.equalizeHist(y)\n",
    "    img_hist_equalized = cv2.merge((y, cr, cb))\n",
    "    img_hist_equalized = cv2.cvtColor(img_hist_equalized, cv2.COLOR_YCrCb2BGR)\n",
    "    return img_hist_equalized\n",
    "\n",
    "def LaplacianOfGaussian(image):\n",
    "    LoG_image = cv2.GaussianBlur(image, (3,3), 0)           # paramter \n",
    "    gray = cv2.cvtColor( LoG_image, cv2.COLOR_BGR2GRAY)\n",
    "    LoG_image = cv2.Laplacian( gray, cv2.CV_8U,3,3,2)       # parameter\n",
    "    LoG_image = cv2.convertScaleAbs(LoG_image)\n",
    "    return LoG_image\n",
    "    \n",
    "def binarization(image):\n",
    "    thresh = cv2.threshold(image,32,255,cv2.THRESH_BINARY)[1]\n",
    "    #thresh = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "    return thresh\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = constrastLimit(image)\n",
    "    image = LaplacianOfGaussian(image)\n",
    "    image = binarization(image)\n",
    "    return image\n",
    "\n",
    "# Find Signs\n",
    "def removeSmallComponents(image, threshold):\n",
    "    #find all your connected components (white blobs in your image)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "\n",
    "    img2 = np.zeros((output.shape),dtype = np.uint8)\n",
    "    #for every component in the image, you keep it only if it's above threshold\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= threshold:\n",
    "            img2[output == i + 1] = 255\n",
    "    return img2\n",
    "\n",
    "def findContour(image):\n",
    "    #find contours in the thresholded image\n",
    "    cnts = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE    )\n",
    "#    print (imutils.is_cv2())\n",
    "#    cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "    cnts = cnts[0]\n",
    "    return cnts\n",
    "\n",
    "def contourIsSign(perimeter, centroid, threshold):\n",
    "    #  perimeter, centroid, threshold\n",
    "    # # Compute signature of contour\n",
    "    result=[]\n",
    "    for p in perimeter:\n",
    "        p = p[0]\n",
    "        distance = sqrt((p[0] - centroid[0])**2 + (p[1] - centroid[1])**2)\n",
    "        result.append(distance)\n",
    "    max_value = max(result)\n",
    "    signature = [float(dist) / max_value for dist in result ]\n",
    "    # Check signature of contour.\n",
    "    temp = sum((1 - s) for s in signature)\n",
    "    temp = temp / len(signature)\n",
    "    if temp < threshold: # is  the sign\n",
    "        return True, max_value + 2\n",
    "    else:                 # is not the sign\n",
    "        return False, max_value + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c92eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropSign(image, coordinate):\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    top = max([int(coordinate[0][1]), 0])\n",
    "    bottom = min([int(coordinate[1][1]), height-1])\n",
    "    left = max([int(coordinate[0][0]), 0])\n",
    "    right = min([int(coordinate[1][0]), width-1])\n",
    "    #print(top,left,bottom,right)\n",
    "    return image[top:bottom,left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLargestSign(image, contours, threshold, distance_theshold):\n",
    "    max_distance = 0\n",
    "    coordinate = None\n",
    "    sign = None\n",
    "#    print (len(contours))\n",
    "#    M = [None]*len(contours)\n",
    "    for c in contours:\n",
    "#        print (type(c))\n",
    "#        print (c.shape)\n",
    "#        print (c.dtype)\n",
    "        M = cv2.moments(c)\n",
    "#        M = cv2.moments(np.uint8(c))\n",
    "        if M[\"m00\"] == 0:\n",
    "            continue\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        is_sign, distance = contourIsSign(c, [cX, cY], 1-threshold)\n",
    "        if is_sign and distance > max_distance and distance > distance_theshold:\n",
    "            max_distance = distance\n",
    "            coordinate = np.reshape(c, [-1,2])\n",
    "            left, top = np.amin(coordinate, axis=0)\n",
    "            right, bottom = np.amax(coordinate, axis = 0)\n",
    "            coordinate = [(left-2,top-2),(right+3,bottom+1)]\n",
    "            sign = cropSign(image,coordinate)\n",
    "    return sign, coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "af902c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization(image, min_size_components, similitary_contour_with_circle, model, current_sign_type): # , count = 0\n",
    "    original_image = image.copy()\n",
    "    binary_image = preprocess_image(image)\n",
    "\n",
    "    binary_image = removeSmallComponents(binary_image, min_size_components)\n",
    "\n",
    "    binary_image = cv2.bitwise_and(binary_image,binary_image, mask=remove_other_color(image))\n",
    "\n",
    "    #binary_image = remove_line(binary_image)\n",
    "\n",
    "    cv2.imshow('BINARY IMAGE', binary_image)\n",
    "    contours = findContour(binary_image)\n",
    "    #signs, coordinates = findSigns(image, contours, similitary_contour_with_circle, 15)\n",
    "    sign, coordinate = findLargestSign(original_image, contours, similitary_contour_with_circle, 15)\n",
    "    \n",
    "    text = \"\"\n",
    "    sign_type = -1\n",
    "    i = 0\n",
    "\n",
    "#     if sign is not None:\n",
    "#         sign_type = getLabel(model, sign)\n",
    "#         sign_type = sign_type if sign_type <= 8 else 8\n",
    "#         text = SIGNS[sign_type]\n",
    "#         cv2.imwrite(str(count)+'_'+text+'.png', sign)\n",
    "\n",
    "    if sign_type > 0 and sign_type != current_sign_type:        \n",
    "        cv2.rectangle(original_image, coordinate[0],coordinate[1], (0, 255, 0), 1)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        cv2.putText(original_image,text,(coordinate[0][0], coordinate[0][1] -15), font, 1,(0,0,255),2,cv2.LINE_4)\n",
    "    return coordinate, original_image, sign_type, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a8ae0c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--similitary_contour_with_circle'], dest='similitary_contour_with_circle', nargs=None, const=None, default=0.65, type=<class 'float'>, choices=None, help='Similitary to a circle', metavar=None)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"NLP Assignment Command Line\")\n",
    "\n",
    "parser.add_argument(\n",
    "  '--file_name',\n",
    "  default= \"./MVI_1049.avi\",\n",
    "  help= \"Video to be analyzed\"\n",
    "  )\n",
    "\n",
    "parser.add_argument(\n",
    "  '--min_size_components',\n",
    "  type = int,\n",
    "  default= 300,\n",
    "  help= \"Min size component to be reserved\"\n",
    "  )\n",
    "\n",
    "\n",
    "parser.add_argument(\n",
    "  '--similitary_contour_with_circle',\n",
    "  type = float,\n",
    "  default= 0.65,\n",
    "  help= \"Similitary to a circle\"\n",
    "  )\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "126c3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/test_comic_locations/batman1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fd73b396",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_sign' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [201]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;241m640\u001b[39m,\u001b[38;5;241m480\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(\"Frame:{}\".format(count))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m coordinate, image, sign_type, text \u001b[38;5;241m=\u001b[39m localization(frame, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m0.65\u001b[39m, svm_clf, \u001b[43mcurrent_sign\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coordinate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(image, coordinate[\u001b[38;5;241m0\u001b[39m],coordinate[\u001b[38;5;241m1\u001b[39m], (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_sign' is not defined"
     ]
    }
   ],
   "source": [
    "frame = cv2.resize(img, (640,480))\n",
    "\n",
    "# print(\"Frame:{}\".format(count))\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "coordinate, image, sign_type, text = localization(frame, 300, 0.65, svm_clf, current_sign)\n",
    "if coordinate is not None:\n",
    "    cv2.rectangle(image, coordinate[0],coordinate[1], (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d5721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
